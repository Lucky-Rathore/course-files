<?xml version='1.0' encoding='utf-8'?>
<chapter display_name="MIT 6.S191 (2023): Recurrent Neural Networks, Transformers, and Attention"><sequential url_name="f945676a27b14b46adc040d8bf31d67e" /><sequential url_name="b6a2b0d0bbb94e22a879ba8095f6872c" /><sequential url_name="04cbfbc88efa4a9f8e6b2c86e005efd4" /><sequential url_name="a537d86b949547738b4017639c6c9972" /><sequential url_name="4051471b18c14167af1bc2d54436764d" /><sequential url_name="eea04ac5298f4c959d3f7f9b6562764b" /><sequential url_name="68930bbecfaf4b72b02d0b314c411923" /><sequential url_name="89c86d42593a44b2bce93651686a3871" /><sequential url_name="83ecf8da02184b1aabc562840f1e1f93" /><sequential url_name="2ed838e7295a493491b61bc5b99d1f3c" /><sequential url_name="8f6f3cbe33e1484289c1cec4f2c83515" /><sequential url_name="cd46cd0ba75f41d09b3e3e1160549718" /><sequential url_name="6dcb76f0b02e4c958742c3349d26d573" /><sequential url_name="30dd283166684c9eb262192290b54adb" /><sequential url_name="07a5d6c2ff6944d0bf1a06ab7bb96525" /><sequential url_name="8053fc6d6632465dab0e79dad10ace49" /><sequential url_name="fa94def63a8d43e1a164ac7f5f8937fd" /><sequential url_name="73a5fb46ca8e459ba602504f100d2053" /><sequential url_name="cb9cce8a46284cf883cbd39d07216775" /></chapter>